{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1588428f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T10:03:53.925790Z",
     "start_time": "2024-05-31T10:03:53.771949Z"
    }
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "def MF_DOWNLOAD(URL, Outpath, Label, Keyword, Need_login, headers={}):\n",
    "    print('########## Prepare to get URL ##########')\n",
    "    if Need_login:\n",
    "        add = urllib.request.Request(url=URL, headers=headers)\n",
    "        content = urllib.request.urlopen(url=add, timeout=10).read().decode(\n",
    "            'utf-8')\n",
    "    else:\n",
    "        content = urllib.request.urlopen(URL).read().decode(\n",
    "            'utf-8') \n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    list_urls = soup.find_all(Label)\n",
    "    urls = []\n",
    "    for i in list_urls:\n",
    "        if Keyword in i.get_text():\n",
    "            urls.append(i.get('href')) \n",
    "            \n",
    "    print('########## Ready to download! ##########')\n",
    "    for i, url in enumerate(urls):\n",
    "        print(\"The file \" + str(i + 1) + \" is downloading! You still have \" +\n",
    "              str(len(urls) - i - 1) + \" files waiting for downloading!\")\n",
    "        file_name = Outpath + url.split('/')[-1]\n",
    "        urllib.request.urlretrieve(URL + url.split('/')[-1], file_name)\n",
    "        time.sleep(1)    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e180ae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T10:04:09.344444Z",
     "start_time": "2024-05-31T10:04:09.335957Z"
    }
   },
   "outputs": [],
   "source": [
    "# An example\n",
    "\n",
    "# output path\n",
    "Outpath = 'C:/'\n",
    "# URL of the web\n",
    "URL = 'https://downloads.psl.noaa.gov/Datasets/20thC_ReanV2/gaussian/monolevel/'\n",
    "\n",
    "# Label & Keyword can be found by: Click Ctrl+U in the web\n",
    "# Location for data url\n",
    "Label = 'a'\n",
    "# Filter keyword\n",
    "Keyword = 'air'\n",
    "# If need login\n",
    "# Cookie & User-Agent can be found by: \n",
    "# Click F12 or Ctrl+Shift+I in the web -> find 'network' -> Find the website -> find 'Cookie' and 'User-Agent \n",
    "Cookieinfo = \"Your Cookie\"\n",
    "User = 'Your User-Agent'\n",
    "headers = {\n",
    "    'Cookie': Cookieinfo, \n",
    "    'User-Agent': User}\n",
    "\n",
    "# Usage\n",
    "MF_DOWNLOAD(URL, Outpath, Label, Keyword, Need_login=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
